\documentclass[paper=a4, fontsize=11pt]{scrartcl} % A4 paper and 11pt font size

\usepackage[english]{babel} % English language/hyphenation
\usepackage{amsmath,amsfonts,amsthm} % Math packages
\usepackage{sectsty} % Allows customizing section commands
\allsectionsfont{\centering \normalfont\scshape} % Make all sections centered, the default font and small caps

\usepackage{fancyhdr} % Custom headers and footers
\usepackage{bm}
\usepackage{upgreek}
\usepackage{tikz}
\usetikzlibrary{shapes, arrows}

\pagestyle{fancyplain} % Makes all pages in the document conform to the custom headers and footers
\fancyhead{} % No page header - if you want one, create it in the same way as the footers below
\fancyfoot[L]{} % Empty left footer
\fancyfoot[C]{} % Empty center footer
\fancyfoot[R]{\thepage} % Page numbering for right footer
\renewcommand{\headrulewidth}{0pt} % Remove header underlines
\renewcommand{\footrulewidth}{0pt} % Remove footer underlines
\setlength{\headheight}{13.6pt} % Customize the height of the header

%-------------------------------
%	TITLE SECTION
%-------------------------------

\newcommand{\horrule}[1]{\rule{\linewidth}{#1}} % Create horizontal rule command with 1 argument of height

\title{
\normalfont \normalsize
\textsc{Brigham Young University} \\ [25pt] % Your university, school and/or department name(s)
\horrule{0.5pt} \\[0.4cm] % Thin top horizontal rule
\huge Practical High Speed Obstacle Avoidance in Unmanned Arieal Vehicals\\ % The assignment title
\horrule{2pt} \\[0.5cm] % Thick bottom horizontal rule
}

\author{James Jackson, Robert Pottorff} % Your name

\date{\normalsize\today} % Today's date or a custom date

\begin{document}

\maketitle % Print the title

\abstract{Practical applications of UAVs are often limited by their ability to react to obstacles at high speeds. Although much progress has been made over the last few decades, current obstacle avoidance methods are either too slow or rely on unreasonable assumptions for some high-speed applications. Leaning on incredible recent successes applying deep reinforcement learning to high dimensional tasks, our agent consists of a deep actor-critic neural network trained using a combination of supervised and reinforcement learning technqiues. We successfully control an agent that can fly up to 72km/h over various simulated obstacle-ridden terrain using only raw sensor data as input. Using inter-network statistics as a component of the cost function, we also demonstrate the successful transfer of learning from networks trained on simualted data, to agents running on real-world data and thereby achieve state-of-the-art results in real-world trials.}

\section{Introduction}

\begin{itemize}
	\item Obstacle avoidance is an essential component of a safe operation of an autonomus agent.
	\item At high speeds, however, obstacle avoidance is critical to many of the practical applications
\end{itemize}
	
\begin{itemize}
	\item At it's heart, obstacle avoidance is about forming a policy $\pi$ that relates an action to a given sensor state $s$.
	\item This often means transforming an often noisy, high dimensional sensor space into a high-level abstraction that can make this mapping tractable.
\end{itemize}
	
\begin{itemize}
	\item Historically, most obstacle avoidance algorithms have relied on hand-crafted, closed-form rules applied to given fixed transformations of the sensor space such as SIFT keypoints [http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=790410]
	\item More recently, some methods have leveraged recent work in deep learning to apply high-level abstractions learned from object recongition tasks [citation needed] to improve results but maintain a standard post-feature processing pipeline.
	\item Few of these methods have shown robustness to sensor choice, particularly at high speeds, and none to our knowlege have studied the impact of specialized high level abstractions learned exclusively for obstacle avoidance.
\end{itemize}

\begin{itemize}	
	\item Our motivation in this work is to show that the right high-dimensional feature space can enable an agent to perform with greater accuracy and at higher speeds than previous methods.
	\item We apply advancements made in reinforcement learning to actively learn high-level representations that maximize performance on obstacle avoidance tasks, enabling us to achieve state-of-the-art performance at high speeds in both simulated and real-world scenarios. 
\end{itemize}

\begin{itemize}
	\item Critical to reinforcement learning methods is the capcity to learn via trial and error, often a serious problem for real-world agents where failure is catostrophic.
	\item To overcome this problem, we also introduce a method for combining real world and simulated data.
	\item The success of reinforcement learning to this domain points the way to a generalized algorithm for high speed control that is robust to sensor choice.
\end{itemize}

\section{Literature Review}

	\subsection{Obstacle Avoidance}

		\begin{itemize}
			\item Traditional Obstacle Avoidance
			\begin{itemize}
				\item Most obstacle avoidance algorigthms have focused on designing a closed-form avoidance rule given specific inputs.
				\item FFLOA~\cite{Scherer2007} - first ROAP, uses a heavy, specialized sensor, awesome results.
				\item Schopferer~\cite{Schopferer2014} - closest to optimal ROAP.  Considers kinematic feasibility of avoidane - What sensor did it use?
				\item Oleynikova~\cite{Oleynikova2015} - Stereo vision FFLOA
				\item Saunders~\cite{Saunders2009} - Local memory Voxel Grid-based planning
				\item Richter et al.~\cite{Richter2014} - Path planning based on learned probabilities of collision and optimizing a dynamic model
				\item Jackson~\cite{CEPA} - aimed at reducing limitations imposed by traditional algorithms
			\end{itemize}
			\item Machine Learning Obstacle Avoidance
			\begin{itemize}			
				\item ALVINN~\cite{Pomerleau1989} - first neural network applied to a land vehicle (ground robot - token reference)
				\item Michels et al.~\cite{Michels2005} performed obstacle avoidance on a ground vehicles, and successfully applied networks trained on simulated and real life data.  However the meshing of this data is weird.  Manually extracted features (ground robot)
				\item Hadsell et al.~\cite{Hadsell2009} used a neural network to classify and avoid obstacles at a distance using a stereo vision algorithm - used a convolutional neural network to extract custom features for obstacle avoidance (ground robot.
				\item Ross~\cite{Ross2013} - Supervised Learning obstacle avoidance from manually extracted features.
				\item Zhang et al.~\cite{Zhang2015} approximated MPC with a neural network using supervised learning (may not apply to our stuff)
				\item Kim et al.~\cite{Kim2015} - Monocular camera of indoor flight using a MAV.  Supplied a dataset - expanded~\cite{Ross2013} with an ``advanced classifer'', used a ConvNet, and tried to get the MAV to find targets on its own.
				\item Giusti et al.~\cite{Guisti2016} demonstrated the application of a DNN which could extract relevant features and follow a previously unknown trail in a forested area.

			\end{itemize}
		\end{itemize}


	\subsection{Neural Networks and Reinforcement Learning}
		Convoultion NN

		Deep Learning \cite{LeCun2015}

		Playing Atari with Deep Reinforcement Learning~\cite{Mnih2013}

		CONTINUOUS CONTROL WITH DEEP REINFORCEMENT LEARNING~\cite{Lillicrap2015}

	\subsection{Transfer Learning}
		Policy Distilation~\cite{Rusu2015}

		Transfer of Style (Gram Matricies)~\cite{Gatys2015}
		
		Deep Compression~\cite{Han2015}

		Progressive Networks


	% \item Introdution to approach (overview)
	% \begin{itemize}
	% 	\item Deep learning has so many parameters, needs tons of data AND reinforcement learning needs failure therefore simulation is practically only option
	% 	\item Simulation is cheap, but comes at the expense of realism
	% 	\item Transfering from simulation to real-life is difficult
	% 	\item therefore - two simulations and demonstrate theory by transfering to high fidelity unreal engine
	% \end{itemize}


\section{Approach} 
\begin{itemize}
	\item what is simulator A?
	\begin{itemize}
		\item built in gazebo
		\item obstacles are pylons and walls randomly placed
		\item second order dynamics for pitch/roll/yaw
		\item first order dynamics for thrust
		\item colision calculation
		\item world is guarnteed to be traversable and meet constraints so that turning radius at n mph is at least x, and \cite{Richter2014}-like 
	\end{itemize}

	\item what is simulator B?
	\begin{itemize}
		\item same as A, but higher fidelity and slower
		\item obstacles are simulated to look like indoor cluttered environments
	\end{itemize}

	\item what does our network look like?
	\begin{itemize}
		\item identical structure to \cite{Lillicrap2015}
		\item hyperparameters
		\item topology
		\item picture
	\end{itemize}

	\item how do we train an agent to succeed in supervised simulator A?
	\begin{itemize}
		\item similar to \cite{Kim2015} except with RRT in lieu of expert pilot 
		\item generate 10m training tuples of (sensor, goal trajectory, expected avoidance trajectory) over 10m (world, optimal trajectory)
		\item account for orientation bias in training tuples and real-life noise in sensor data
		\item cost function
		\item network details
	\end{itemize}

	\item how do we train an agent to succeed in unsupervised (RL) simulator A?
	\begin{itemize}
		\item similar to \cite{Lillicrap2015} except with pre-trained network and UAV task instead of whatever they use
		\item new worlds generated every episode similar to supervised worlds
		\item cost function / q learning math
		\item terminal state is defined as 5 meter radius to goal
		\item discritized reward every 10 meters vs change in inverse distance
		\item why discritized reward?
		\item negative reward on crash / death
	\end{itemize}

	\item how do we transfer knowlege from network A to network B
	\begin{itemize}
		\item network A (trained for simulation) has identical structure to network B (trained for real-world)
		\item train network A using simulation
		\item gather data for network B
		\item train network B with additional cost of minimizing gram matrix similarity
	\end{itemize}

\end{itemize}


\section{Results}

\section{Discussion}


\section{Appendix}


\bibliography{./library}
\bibliographystyle{ieeetr}

\end{document}