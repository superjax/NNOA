@article{Matsumoto2015,
abstract = {The growing public interest for Unmanned Aircraft Systems (UAS) applications has stimulated the debate over the integration of this kind of aircraft into the civil aviation system. However, the concept of not having a human pilot inside the aircraft presents uncertainties that may impede the creation of proper regulation. Having safety as the main concern for civil aviation, one important principle of aviation to be addressed in an UAS is collision avoidance, a traditionally pilot-dependent functionality. In this regard, as a possible substitute for the pilot in the aircraft, we propose a method for implementing a learning-based autonomous control system focused in guaranteeing collision avoidance. Regarding that safety aspect, we expect such system to be able to compensate for the lack of a human pilot in the aircraft. The proposed approach utilizes the concept of 'Learning from Demonstration' in order to define a behaviour for the autonomous aircraft based on manoeuvres commanded by a human. Therefore, the proposed approach would represent a possible implementation of an autonomous unmanned aircraft that presents the same collision avoidance capabilities observed in (human-based) civil aviation. Additionally, we identify metrics that can be used to select a suitable learning-based method and to compare its performance to those observed in manned aircraft.},
author = {Matsumoto, Thiago Toshio and Vismari, Lucio Flavio and Gimenes, Ricardo Alexandre Veiga and de Almeida, Jorge Rady and Camargo, Joao B.},
doi = {10.1109/DSN-W.2015.29},
file = {:home/capn/Documents/07272560.pdf:pdf},
isbn = {978-1-4673-8044-7},
journal = {2015 IEEE International Conference on Dependable Systems and Networks Workshops},
keywords = {UAS,safety,sense and avoid},
pages = {96--103},
title = {{A Learning-Based Autonomous Control System Approach for Collision Avoidance within an Unmanned Aircraft}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7272560},
year = {2015}
}
@article{Pomerleau1989,
abstract = {ALVINN (Autonomous Land Vehicle In a Neural Network) is a 3-layer back-propagation network designed for the task of road following. Currently ALVINN takes images from a camera and a laser range finder as input and produces as output the direction the vehicle should travel in order to follow the road. Training has been conducted using simulated road images. Successful tests on the Carnegie Mellon autonomous navigation test vehicle indicate that the network can effectively follow real roads under certain field conditions. The representation developed to perform the task differs dramatically when the network is trained under various conditions, suggesting the possibility of a novel adaptive autonomous navigation system capable of tailoring its processing to the conditions at hand.},
author = {Pomerleau, Dean a},
file = {:home/capn/Documents/ALVINN an autonomous land vehicle in a neural network.pdf:pdf},
isbn = {1-558-60015-9},
journal = {Advances in Neural Information Processing Systems 1},
pages = {305--313},
title = {{Alvinn: An autonomous land vehicle in a neural network}},
year = {1989}
}
@article{Guisti2016,
abstract = {Download Citation Email Print Request Permissions We study the problem of perceiving forest or mountain trails from a single monocular image acquired from the viewpoint of a robot traveling on the trail itself. Previous literature focused on trail segmentation, and used low-level features such as image saliency or appearance contrast; we propose a different approach based on a deep neural network used as a supervised image classifier. By operating on the whole image at once, our system outputs the main direction of the trail compared to the viewing direction. Qualitative and quantitative results computed on a large real-world dataset (which we provide for download) show that our approach outperforms alternatives, and yields an accuracy comparable to the accuracy of humans that are tested on the same image classification task. Preliminary results on using this information for quadrotor control in unseen trails are reported. To the best of our knowledge, this is the first letter that describes an approach to perceive forest trials, which is demonstrated on a quadrotor micro aerial vehicle.},
author = {Guisti Alessandro, Guzzi Jerome, Circesan Dan C., He Fang-Lin, Rodriguez Juan P., Fontana Flavio, Faessler Matthias, Forster Christian, Schmidhuber Jurgen, Di Caro Gianni, Scaramuzza Davide, Gambardella Luca M.},
doi = {10.1109/LRA.2015.2509024},
file = {:home/capn/Documents/07358076.pdf:pdf},
issn = {2377-3766},
journal = {Robotics and Automation Letters},
number = {2},
pages = {661--667},
title = {A Machine Learning Approach to Visual Perception of Forest Trails for Mobile Robots},
volume = {1},
year = {2016}
}
@article{Hadsell2009,
abstract = {Most vision-based approaches to mobile robotics suffer from the limitations imposed by stereo obstacle detection, which is short range and prone to failure. We present a self-supervised learning process for long-range vision that is able to accurately classify complex terrain at distances up to the horizon, thus allowing superior strategic planning. The success of the learning process is due to the self-supervised training data that are generated on every frame: robust, visually consistent labels from a stereo module; normalized wide-context input windows; and a discriminative and concise feature representation. A deep hierarchical network is trained to extract informative and meaningful features from an input image, and the features are used to train a real-time classifier to predict traversability. The trained classifier sees obstacles and paths from 5 to more than 100 m, far beyond the maximum stereo range of 12 m, and adapts very quickly to new environments. The process was developed and tested on the LAGR (Learning Applied to Ground Robots) mobile robot. Results from a ground truth data set, as well as field test results, are given. {\textcopyright} 2009 Wiley Periodicals, Inc.},
author = {Hadsell, Raia and Sermanet, Pierre and Ben, Jan and Erkan, Ayse and Scoffier, Marco and Kavukcuoglu, Koray and Muller, Urs and LeCun, Yann},
doi = {10.1002/rob.20276},
file = {:home/capn/Documents/hadsell-jfr-09.pdf:pdf},
isbn = {9783902661623},
issn = {1556-4967},
journal = {Journal of Field Robotics},
number = {2},
pages = {120--144},
title = {{Learning long-range vision for autonomous off-road driving}},
url = {http://onlinelibrary.wiley.com/doi/10.1002/rob.20276/abstract http://onlinelibrary.wiley.com/doi/10.1002/rob.20276/pdf},
volume = {26},
year = {2009}
}
@article{Matsumoto2014,
abstract = {The growing public interest for Unmanned Air Systems (UAS) applications has stimulated the debate over the integration of this kind of aircraft into the civil aviation system. However, the concept of not having a human pilot inside the aircraft presents uncertainties that may impede the creation of proper regulation. Having safety as the main concern for civil aviation, one important principle of aviation to be addressed in an UAS is collision avoidance, a traditionally pilot-dependent functionality. Therefore, we propose a method for implementing a learning-based Piloting Autonomous System. The proposed approach utilizes the concept of `Learning from Demonstration' in order to define a behavior for the autonomous aircraft based on the maneuvers executed by a human pilot. By doing so, we expect the Piloting Autonomous System to be able to compensate for the lack of a human pilot in the aircraft. Therefore, the proposed approach would represent a possible implementation of an autonomous UAS that presents the same safety levels observed in (human-based) civil aviation. Additionally, we identify metrics that can be used to select a suitable learning-based method and to compare its performance to those observed in manned aircraft.},
author = {Matsumoto, Thiago T. and Vismari, Lucio F. and Camargo, Joao B.},
doi = {10.1109/ICUAS.2014.6842256},
file = {:home/capn/Documents/06842256.pdf:pdf},
isbn = {9781479923762},
journal = {2014 International Conference on Unmanned Aircraft Systems, ICUAS 2014 - Conference Proceedings},
keywords = {UAS,collision avoidance,piloting autonomous systems,safety,sense and avoid},
pages = {195--199},
title = {{A method to implement and to evaluate a learning-based piloting autonomous system for UAS}},
year = {2014}
}
@article{Richter2014,
abstract = {We present a motion planning algorithm for dynamic vehicles navigating through unknown environments. We focus on the scenario in which a fast-moving car attempts to navigate from a start location to a set of goal coordinates in minimum time with no prior information about the environment, building a map in real time from onboard sensor data. Whereas existing planners for exploration confine themselves to a conservative set of constraints to guarantee safety around unknown regions of the environment, we instead learn a hazard function from data, which maps the vehicle's dynamic state and current environment knowledge to a probability of collision. We perform receding horizon planning in which the objective function is evaluated in expectation over those learned probabilities of collision. Our algorithm demonstrates sensible emergent behaviors, like swinging wide around blind corners, slowing down near the map frontier, and accelerating in regions of high visibility. Our algorithm is capable of navigating from start to goal much more quickly than the conservative baseline planner without sacrificing safety. We demonstrate our algorithm on a 1:8-scale high-performance RC car equipped with a planar laser range-finder and inertial measurement unit, reaching speeds of 4m/s in unknown, indoor spaces. A video of experimental results is available at: http: //groups.csail.mit.edu/rrg/nav{\_}learned{\_}prob{\_}collision.},
author = {Richter, Charles and Ware, John and Roy, Nicholas},
doi = {10.1109/ICRA.2014.6907760},
file = {:home/capn/Documents/Richter{\_}ICRA14.pdf:pdf},
isbn = {978-1-4799-3685-4},
issn = {10504729},
journal = {Proceedings - IEEE International Conference on Robotics and Automation},
number = {Icra},
pages = {6114--6121},
title = {{High-speed autonomous navigation of unknown environments using learned probabilities of collision}},
year = {2014}
}
@article{Michels2005,
abstract = {We consider the task of driving a remote control car at high speeds through unstructured outdoor environments. We present an approach in which supervised learning is first used to estimate depths from single monocular images. The learning algorithm can be trained either on real camera images labeled with ground-truth distances to the closest obstacles, or on a training set consisting of synthetic graphics images. The resulting algorithm is able to learn monocular vision cues that accurately estimate the relative depths of obstacles in a scene. Reinforcement learning/policy search is then applied within a simulator that renders synthetic scenes. This learns a control policy that selects a steering direction as a function of the vision system's output. We present results evaluating the predictive ability of the algorithm both on held out test data, and in actual autonomous driving experiments.},
author = {Michels, Jeff and Saxena, Ashutosh and Ng, Andrew Y.},
doi = {10.1145/1102351.1102426},
file = {:home/capn/Documents/icml{\_}obstacleavoidance.pdf:pdf},
isbn = {1595931805},
issn = {{\textless}null{\textgreater}},
journal = {Proceedings of the 22nd international conference on Machine learning - ICML '05},
number = {Suppl 1},
pages = {593--600},
title = {{High speed obstacle avoidance using monocular vision and reinforcement learning}},
url = {http://dl.acm.org/citation.cfm?id=1102351.1102426},
volume = {3},
year = {2005}
}
@article{Levine2014,
abstract = {Direct policy search methods offer the promise of automatically learning controllers for complex, high-dimensional tasks. However, prior applications of policy search often required specialized, low-dimensional policy classes, limiting their generality. In this work, we introduce a policy search algorithm that can directly learn high-dimensional, general-purpose policies, represented by neural networks. We formulate the policy search problem as an optimization over trajectory distributions, alternating between optimizing the policy to match the trajectories, and optimizing the trajectories to match the policy and minimize expected cost. Our method can learn policies for complex tasks such as bipedal push recovery and walking on uneven terrain, while outperforming prior methods.},
author = {Levine, Sergey and Koltun, Vladlen},
file = {:home/capn/Documents/icml2014c2{\_}levine14.pdf:pdf},
isbn = {9781634393973},
journal = {Proceedings of the 31st International Conference on Machine Learning (ICML-14)},
pages = {829--837},
title = {{Learning Complex Neural Network Policies with Trajectory Optimization}},
url = {http://jmlr.org/proceedings/papers/v32/levine14.pdf},
volume = {32},
year = {2014}
}
@article{Ross2013,
abstract = {Autonomous navigation for large Unmanned Aerial Vehicles (UAVs) is fairly straight-forward, as expensive sensors and monitoring devices can be employed. In contrast, obstacle avoidance remains a challenging task for Micro Aerial Vehicles (MAVs) which operate at low altitude in cluttered environments. Unlike large vehicles, MAVs can only carry very light sensors, such as cameras, making autonomous navigation through obstacles much more challenging. In this paper, we describe a system that navigates a small quadrotor helicopter autonomously at low altitude through natural forest environments. Using only a single cheap camera to perceive the environment, we are able to maintain a constant velocity of up to 1.5m/s. Given a small set of human pilot demonstrations, we use recent state-of-the-art imitation learning techniques to train a controller that can avoid trees by adapting the MAVs heading. We demonstrate the performance of our system in a more controlled environment indoors, and in real natural forest environments outdoors.},
annote = {This method basically teaches the quad to fly itself based on the actions of an expert pilot.

It uses the DAgger algorithm to expand the training set to include data captured during autonomous flight, not seen during the training segment.

Off-board processing done with an ARDrone, using a forward-facing monocular camera},
archivePrefix = {arXiv},
arxivId = {arXiv:1211.1690v1},
author = {Ross, Stephane and Melik-Barkhudarov, Narek and Shankar, Kumar Shaurya and Wendel, Andreas and Dey, Debadeepta and Bagnell, J. Andrew and Hebert, Martial},
doi = {10.1109/ICRA.2013.6630809},
eprint = {arXiv:1211.1690v1},
file = {:home/capn/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ross et al. - 2013 - Learning monocular reactive UAV control in cluttered natural environments.pdf:pdf},
isbn = {9781467356411},
issn = {10504729},
journal = {Proceedings - IEEE International Conference on Robotics and Automation},
pages = {1765--1772},
title = {{Learning monocular reactive UAV control in cluttered natural environments}},
year = {2013}
}
@article{Kim2015,
abstract = {Autonomous indoor navigation of Micro Aerial Vehicles (MAVs) possesses many challenges. One main reason is that GPS has limited precision in indoor environments. The additional fact that MAVs are not able to carry heavy weight or power consuming sensors, such as range finders, makes indoor autonomous navigation a challenging task. In this paper, we propose a practical system in which a quadcopter autonomously navigates indoors and finds a specific target, i.e., a book bag, by using a single camera. A deep learning model, Convolutional Neural Network (ConvNet), is used to learn a controller strategy that mimics an expert pilot's choice of action. We show our system's performance through real-time experiments in diverse indoor locations. To understand more about our trained network, we use several visualization techniques.},
archivePrefix = {arXiv},
arxivId = {1511.04668},
author = {Kim, Dong Ki and Chen, Tsuhan},
eprint = {1511.04668},
file = {:home/capn/Documents/1511.04668v2.pdf:pdf},
title = {{Deep Neural Network for Real-Time Autonomous Indoor Navigation}},
url = {http://arxiv.org/abs/1511.04668},
year = {2015}
}
@article{Zhang2015,
abstract = {Model predictive control (MPC) is an effective method for controlling robotic systems, particularly autonomous aerial vehicles such as quadcopters. However, application of MPC can be computationally demanding, and typically requires estimating the state of the system, which can be challenging in complex, unstructured environments. Reinforcement learning can in principle forego the need for explicit state estimation and acquire a policy that directly maps sensor readings to actions, but is difficult to apply to underactuated systems that are liable to fail catastrophically during training, before an effective policy has been found. We propose to combine MPC with reinforcement learning in the framework of guided policy search, where MPC is used to generate data at training time, under full state observations provided by an instrumented training environment. This data is used to train a deep neural network policy, which is allowed to access only the raw observations from the vehicle's onboard sensors. After training, the neural network policy can successfully control the robot without knowledge of the full state, and at a fraction of the computational cost of MPC. We evaluate our method by learning obstacle avoidance policies for a simulated quadrotor, using simulated onboard sensors and no explicit state estimation at test time.},
archivePrefix = {arXiv},
arxivId = {1509.06791},
author = {Zhang, Tianhao and Kahn, Gregory and Levine, Sergey and Abbeel, Pieter},
doi = {10.1103/PhysRevLett.115.104301},
eprint = {1509.06791},
file = {:home/capn/Documents/1509.06791v2.pdf:pdf},
isbn = {9781467380256},
title = {{Learning Deep Control Policies for Autonomous Aerial Vehicles with MPC-Guided Policy Search}},
url = {http://arxiv.org/abs/1509.06791},
year = {2015}
}

@inproceedings{Schopferer2014,
annote = {Basically a really fast planner that doesn't need reactive avoidance.

Creates a full map of history

Not really the same thing as what we are doing.

Uses Cubic splines to create path, which is pretty interesting},
author = {Schopferer, Simon and Adolf, Florian Michael},
booktitle = {2014 International Conference on Unmanned Aircraft Systems, ICUAS 2014 - Conference Proceedings},
doi = {10.1109/ICUAS.2014.6842269},
file = {:home/capn/Downloads/06842269.pdf:pdf},
isbn = {9781479923762},
keywords = {Cubic Splines,Online Navigation,Trajectory Planning,UAS,Unmanned Rotorcraft},
pages = {305--316},
title = {{Rapid trajectory time reduction for unmanned rotorcraft navigating in unknown terrain}},
year = {2014}
}
@article{Stentz1994,
author = {Stentz, Anthony},
file = {::},
number = {September},
pages = {30},
title = {{The D * Algorithm for Real-Time Planning of Optimal Traverses Table o f Contents}},
year = {1994}
}
@article{Saunders2009,
abstract = {Traditional sensors for obstacle detection on aircraft, such as radar, are too heavy for fixed wing micro air vehicles and make obstacle detection and avoidance a difficult problem. EO/IR cameras are small and lightweight enough to offer an alternative to heavy sensors. Vision processing available on a ground station provides range and bearing to nearby obstacles. We propose a nonlinear guidance law based on movement of obstacles in the camera field-of-view to "push" the obstacles to the edge of the camera field-of-view and thus avoid collision. As the MAV passes obstacles, the original course is resumed. The guidance strategy is demonstrated in simulation and flight test. This reactive method intended for use in conjunction with high level path planners.},
author = {Saunders, J and Beard, R and Byrne, J},
doi = {10.1109/ACC.2009.5160535},
file = {:home/capn/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Saunders, Beard, Byrne - 2009 - Vision-based Reactive Multiple Obstacle Avoidance for Micro Air Vehicles.pdf:pdf},
isbn = {0743-1619},
issn = {0743-1619},
journal = {2009 American Control Conference, Vols 1-9},
keywords = {mobile robot,navigation,probabilistic roadmaps},
pages = {5253--5258},
title = {{Vision-based Reactive Multiple Obstacle Avoidance for Micro Air Vehicles}},
url = {{\textless}Go to ISI{\textgreater}://000270044902211},
year = {2009}
}
@article{Deming2004,
abstract = {Semi-autonomous to fully autonomous robots rely on some form of data collection to operate in their environment. This has traditionally been accomplished using sonar or infra-red sensors to measure the robot's proximity to nearby objects. The most recent of efforts rely on sophisticated sensors, such as LIDAR and stereo vision, and result in solutions which are both expensive economically and computationally. Furthermore, these approaches often provide an overflow of data requiring a great deal of processing. This paper discusses an alternative method using a single camera sampling images periodically to calculate the flow within an image and provide sufficient information to allow a small autonomous robot to navigate a corridor and react to obstacles. This method was implemented on a small robotic platform within an RT-Linux environment. Image data was collected using a CMUCam.},
author = {Deming, J R and Bruder, S},
doi = {10.1109/ICMLA.2004.1383516},
file = {::},
isbn = {0780388232},
journal = {Machine Learning and Applications, 2004. Proceedings. 2004 International Conference on},
keywords = {Cameras,Image motion analysis,Image sampling,Intelligent robots,Intelligent systems,Mobile robots,Optical sensors,Robot sensing systems,Robot vision systems,Sonar},
pages = {215--219},
title = {{Obstacle avoidance using image flow in an RT-Linux environment in a PC-104 platform}},
url = {http://ieeexplore.ieee.org/ielx5/9504/30147/01383516.pdf?tp={\&}arnumber=1383516{\&}isnumber=30147},
year = {2004}
}
@article{Kavraki1996,
abstract = {A new motion planning method for robots in static workspaces is$\backslash$r$\backslash$npresented. This method proceeds in two phases: a learning phase and a$\backslash$r$\backslash$nquery phase. In the learning phase, a probabilistic roadmap is$\backslash$r$\backslash$nconstructed and stored as a graph whose nodes correspond to$\backslash$r$\backslash$ncollision-free configurations and whose edges correspond to feasible$\backslash$r$\backslash$npaths between these configurations. These paths are computed using a$\backslash$r$\backslash$nsimple and fast local planner. In the query phase, any given start and$\backslash$r$\backslash$ngoal configurations of the robot are connected to two nodes of the$\backslash$r$\backslash$nroadmap; the roadmap is then searched for a path joining these two$\backslash$r$\backslash$nnodes. The method is general and easy to implement. It can be applied to$\backslash$r$\backslash$nvirtually any type of holonomic robot. It requires selecting certain$\backslash$r$\backslash$nparameters (e.g., the duration of the learning phase) whose values$\backslash$r$\backslash$ndepend on the scene, that is the robot and its workspace. But these$\backslash$r$\backslash$nvalues turn out to be relatively easy to choose, Increased efficiency$\backslash$r$\backslash$ncan also be achieved by tailoring some components of the method (e.g.,$\backslash$r$\backslash$nthe local planner) to the considered robots. In this paper the method is$\backslash$r$\backslash$napplied to planar articulated robots with many degrees of freedom.$\backslash$r$\backslash$nExperimental results show that path planning can be done in a fraction$\backslash$r$\backslash$nof a second on a contemporary workstation ({\&}ap;150 MIPS), after learning$\backslash$r$\backslash$nfor relatively short periods of time (a few dozen seconds)},
author = {Kavraki, L.E. and Kavraki, L.E. and Svestka, P. and Svestka, P. and Latombe, J.-C. and Latombe, J.-C. and Overmars, M.H. and Overmars, M.H.},
doi = {10.1109/70.508439},
file = {::},
isbn = {1042-296X},
issn = {1042296X},
journal = {Robotics and Automation, IEEE Transactions on},
number = {4},
pages = {566 -- 580},
pmid = {23425417},
title = {{Probabilistic roadmaps for path planning in high-dimensional configuration spaces}},
url = {http://ieeexplore.ieee.org/xpls/abs{\_}all.jsp?arnumber=508439},
volume = {12},
year = {1996}
}
@article{Grzonka2012,
abstract = {Recently, there has been increased interest in the de- velopment of autonomous flying vehicles. However, as most of the proposed approaches are suitable for outdoor operation, only a few techniques have been designed for indoor environments, where the systems cannot rely on the Global Positioning System (GPS) and, therefore, have to use their exteroceptive sensors for navigation. In this paper, we present a general navigation system that enables a small-sized quadrotor system to autonomously operate in indoor environments. To achieve this, we systematically extend and adapt techniques that have been successfully applied on ground robots. We describe all algorithms and present a broad set of experiments, which illustrate that they enable a quadrotor robot to reliably and autonomously navigate in indoor environments.},
annote = {Path Planning OA
Cell-Based OA
Reactive Planner Based on something in a Book

Talks about how their OA avoids obstacles, but could back into an obstacle, not viewed by the sensor.

Plans paths based on the D* algorithm},
author = {Grzonka, Slawomir and Grisetti, Giorgio and Burgard, Wolfram},
doi = {10.1109/TRO.2011.2162999},
file = {:home/capn/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Grzonka, Grisetti, Burgard - 2012 - A fully autonomous indoor quadrotor.pdf:pdf},
isbn = {9788496100275},
issn = {15523098},
journal = {IEEE Transactions on Robotics},
keywords = {Navigation,quadrotor,simultaneous localization and mapping (SLAM),unmanned aerial vehicle (UAV)},
number = {1},
pages = {90--100},
title = {{A fully autonomous indoor quadrotor}},
volume = {28},
year = {2012}
}
@article{Hrabar2011b,
abstract = {We present a goal-directed 3D reactive obstacle avoidance algorithm specifically designed for Rotorcraft Unmanned Aerial Vehicles (RUAVs) that fly point-to-point type trajectories. The algorithm detects potential collisions within a cylindrical Safety Volume projected ahead of the UAV. This is done in a 3D occupancy map representation of the environment. An expanding elliptical search is performed to find an Escape Point; a waypoint which offers a collision free route past obstacles and towards a goal waypoint. An efficient occupied voxel checking technique is employed which approximates the Safety Volume by a series of spheres, and uses an approximate nearest neighbour search in a Bkd-tree representation of the occupied voxels. Tests show the algorithm can typically find an Escape Point in under 100 ms using onboard UAV processing for a cluttered environment with 20 000 occupied voxels. Successful collision avoidance results are presented from simulation experiments and from flights with an autonomous helicopter equipped with stereo and laser range sensors.},
author = {Hrabar, Stefan},
doi = {10.1109/IROS.2011.6048312},
file = {:home/capn/Downloads/06094629.pdf:pdf},
isbn = {9781612844541},
issn = {2153-0858},
journal = {IEEE International Conference on Intelligent Robots and Systems},
pages = {4967--4974},
title = {{Reactive obstacle avoidance for rotorcraft UAVs}},
year = {2011}
}
@article{Macallister2013,
abstract = {Operating micro aerial vehicles (MAVs) outside of the bounds of a rigidly controlled lab environment, specifically one that is unstructured and contains unknown obstacles, poses a number of challenges. One of these challenges is that of quickly determining an optimal (or nearly so) path from the MAVs current position to a designated goal state. Past work in this area using full-size unmanned aerial vehicles (UAVs) has predominantly been performed in benign environments. However, due to their small size, MAVs are capable of operating in indoor environments which are more cluttered. This requires planners to account for the vehicle heading in addition to its spatial position in order to successfully navigate. In addition, due to the short flight times of MAVs along with the inherent hazards of operating in close proximity to obstacles, we desire the trajectories to be as cost-optimal as possible. Our approach uses an anytime planner based on A* that performs a graph search on a four-dimensional (4-D) (x,y,z, heading) lattice. This allows for the generation of close-to-optimal trajectories based on a set of precomputed motion primitives along with the capability to provide trajectories in real-time allowing for on-the-fly re-planning as new sensor data is received. We also account for arbitrary vehicle shapes, permitting the use of a non-circular footprint during the planning process. By not using the overly conservative circumscribed circle for collision checking, we are capable of successfully finding optimal paths through cluttered environments including those with narrow hallways. Analytically, we show that our planner provides bounds on the sub-optimality of the solution it finds. Experimentally, we show that the planner can operate in real-time in both a simulated and real-world cluttered environments.},
annote = {Focused on creating optimal paths through obstacles.

Does not require a circular footprint, as assumed by many OA algorithms

Ran RRT* through the current visible map

No Reactive layer

Some failures in simulation

Built full map},
author = {Macallister, Brian and Butzke, Jonathan and Kushleyev, Alex and Pandey, Harsh and Likhachev, Maxim},
doi = {10.1109/ICRA.2013.6631131},
file = {:home/capn/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Macallister et al. - 2013 - Path planning for non-circular micro aerial vehicles in constrained environments.pdf:pdf},
isbn = {9781467356411},
issn = {10504729},
journal = {Proceedings - IEEE International Conference on Robotics and Automation},
pages = {3933--3940},
title = {{Path planning for non-circular micro aerial vehicles in constrained environments}},
year = {2013}
}
@article{King2009,
abstract = {For a robot with a circular footprint, obstacles in a map can be inflated by the radius of the footprint, and planning can treat the robot as a point robot. Many robotic vehicles however have non-circular footprints. When operating in cluttered spaces it therefore becomes important to evaluate the footprint of these robots against a cost map. This evaluation is one of the major computational burdens in planning for robots whose footprints can not be assumed to be circular. In this paper, we propose an efficient method for evaluating a footprint of the robot against a cost map. Our method involves a transformation of the set of points covered by the footprint of the robot into two sets of points: points that should be evaluated against the cost map with inflated obstacles, and points that should be evaluated against the original cost map. The cumulative number of these points is much smaller than the number of points in the original footprint of the robot. Moreover, the method automatically reduces the robot to a single point when its footprint is circular. On the theoretical side, the paper proves the correctness of our method. On the experimental side, the paper shows that the method results in a significant speedup.},
author = {King, Jennifer and Likhachev, Maxim},
doi = {10.1109/IROS.2009.5354074},
file = {:home/capn/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/King, Likhachev - 2009 - Efficient cost computation in cost map planning for non-circular robots.pdf:pdf},
isbn = {9781424438044},
journal = {2009 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS 2009},
pages = {3924--3930},
title = {{Efficient cost computation in cost map planning for non-circular robots}},
year = {2009}
}
@article{Goerzen2012b,
author = {Goerzen, Chad and Whalley, Matthew},
file = {:home/capn/Downloads/ICUAS2012{\_}Goerzen.pdf:pdf},
journal = {Proceedings of the 2012 International Conference on Unmanned Aircraft Systems (ICUAS), Philadelphia},
title = {{Sensor Requirements for Autonomous Flight}},
url = {http://uarc.ucsc.edu/flight-control/libofn/papers/ICUAS2012{\_}Goerzen.pdf},
year = {2012}
}
@article{Koenig2002,
abstract = {Incremental heuristic search methods use heuristics to focus their search and reuse information from previous searches to find solutions to series of similar search tasks much faster than is possible by solving each search task from scratch. In this paper, we apply Lifelong Planning A* to robot navigation in unknown terrain, including goal-directed navigation in unknown terrain and mapping of unknown terrain. The resulting D* Lite algorithm is easy to understand and analyze. It implements the same behavior as Stentz' Focussed Dynamic A* but is algorithmically different. We prove properties about D* Lite and demonstrate experimentally the advantages of combining incremental and heuristic search for the applications studied. We believe that these results provide a strong foundation for further research on fast replanning methods in artificial intelligence and robotics.},
author = {Koenig, S and Likhachev, M},
file = {::},
isbn = {0262511290},
journal = {Proceedings of the Eighteenth National Conference on Artificial Intelligence},
keywords = {D* Lite;Graph;Search;Algorithm;Dynamic;Path planni},
pages = {476--483},
title = {{D* Lite}},
url = {http://www.aaai.org/Library/AAAI/2002/aaai02-072.php},
year = {2002}
}
@article{Bachrach2010,
abstract = {This paper presents our solution for enabling a quadrotor helicopter, equipped with a laser rangefinder sensor, to autonomously explore and map unstructured and unknown indoor environments. While these capabilities are already commodities on ground vehicles, air vehicles seeking the same performance face unique challenges. In this paper, we describe the difficulties in achieving fully autonomous helicopter flight, highlighting the differences between ground and helicopter robots that make it difficult to use algorithms that have been developed for ground robots. We then provide an overview of our solution to the key problems, including a multilevel sensing and control hierarchy, a high-speed laser scan-matching algorithm, an EKF for data fusion, a high-level SLAM implementation, and an exploration planner. Finally, we show experimental results demonstrating the helicopter's ability to navigate accurately and autonomously in unknown environments.},
annote = {GMapping on a Quad
- Obstacle Map
- Memory of Map

Not Reactive

Used CARMENT Toolkit to plan paths},
author = {Bachrach, Abraham and He, Ruijie and Roy, Nicholas},
doi = {10.1260/175682909790291492},
file = {:home/capn/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bachrach, He, Roy - 2010 - Autonomous Flight in Unknown Indoor Environments.pdf:pdf},
isbn = {1756-8293},
issn = {1756-8293},
journal = {International Journal of Micro Air Vehicles},
number = {4},
pages = {217--228},
title = {{Autonomous Flight in Unknown Indoor Environments}},
volume = {1},
year = {2010}
}
@article{Scherer2007,
abstract = {Safe autonomous flight is essential for widespread acceptance of aircraft that must fly close to the ground. We have developed a method of collision avoidance that can be used in three dimensions in much the same way as autonomous ground vehicles that navigate over unexplored terrain. Safe navigation is accomplished by a combination of online environmental sensing, path planning and collision avoidance. Here we report results with an autonomous helicopter that operates at low elevations in uncharted environments some of which are densely populated with obstacles such as buildings, trees and wires. We have recently completed over 1000 successful runs in which the helicopter traveled between coarsely specified waypoints separated by hundreds of meters, at speeds up to 10 meters/sec at elevations of 5-10 meters above ground level. The helicopter safely avoids large objects like buildings and trees but also wires as thin as 6 mm. We believe this represents the first time an air vehicle has traveled this fast so close to obstacles. Here we focus on the collision avoidance method that learns to avoid obstacles by observing the performance of a human operator.},
annote = {Most Similar OA to mine
Uses a "human inspired" Obstacle avoidance
Reactive OA

Assigns obstacles Spherical Coordinates
- Adds up repulsion and attraction functions
- Exponentially adds/subtracts

Obstacle position is calculated from an evidence grid

Lots of constants to tune
- "learned" these constants by simulating against a pilot's judgement and optimized for constants

Really try hard to keep airspeed up - no coming to perfect hovers

Reactive Planner has the final say

Reactive Plannner could not make it around large obstacles by itself - it would oscillate otherwise

used a "3D Dodger" to avoid in all 3 dimensions},
author = {Scherer, Sebastian and Singh, Sanjiv and Chamberlain, Lyle and Saripalli, Srikanth},
doi = {10.1109/ROBOT.2007.363619},
file = {:home/capn/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Scherer et al. - 2007 - Flying fast and low among obstacles.pdf:pdf},
isbn = {1424406021},
issn = {10504729},
journal = {Proceedings - IEEE International Conference on Robotics and Automation},
pages = {2023--2029},
title = {{Flying fast and low among obstacles}},
year = {2007}
}
@misc{Barraquand1991,
abstract = {The authors investigate a path planning approach that consists of concurrently building and searching a graph connecting the local minima of a numerical potential field defined over the robot's configuration space. They describe techniques for constructing 'good' potentials and efficient methods for dealing with the local minima of these functions. These techniques have been implemented in fast planners that can deal with single and/or multiple robot systems with few and/or many degrees of freedom. Some experimental results with these planners are described.},
author = {Barraquand, J. and Langlois, B. and Latombe, J.-C.},
booktitle = {Fifth International Conference on Advanced Robotics 'Robots in Unstructured Environments},
doi = {10.1109/ICAR.1991.240539},
file = {::},
isbn = {0-7803-0078-5},
issn = {0018-9472},
pages = {1012--1017 vol.2},
title = {{Numerical potential field techniques for robot path planning}},
url = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=240539},
year = {1991}
}
@article{Leishman2014,
author = {Leishman, Robert C. and McLain, Timothy W.},
doi = {10.2514/1.I010236},
file = {::},
issn = {2327-3097},
journal = {Journal of Aerospace Information Systems},
pages = {1--17},
title = {{Multiplicative Extended Kalman Filter for Relative Rotorcraft Navigation}},
url = {http://arc.aiaa.org/doi/abs/10.2514/1.I010236},
year = {2014}
}
@article{Koenig2005a,
abstract = {Mobile robots often operate in domains that are only incompletely known, for example, when they have to move from given start coordinates to given goal coordinates in unknown terrain. In this case, they need to be able to replan quickly as their knowledge of the terrain changes. Stentz' Focussed Dynamic A{\textless}sup{\textgreater}*{\textless}/sup{\textgreater} (D{\textless}sup{\textgreater}*{\textless}/sup{\textgreater}) is a heuristic search method that repeatedly determines a shortest path from the current robot coordinates to the goal coordinates while the robot moves along the path. It is able to replan faster than planning from scratch since it modifies its previous search results locally. Consequently, it has been extensively used in mobile robotics. In this article, we introduce an alternative to D{\textless}sup{\textgreater}*{\textless}/sup{\textgreater} that determines the same paths and thus moves the robot in the same way but is algorithmically different. D{\textless}sup{\textgreater}*{\textless}/sup{\textgreater} Lite is simple, can be rigorously analyzed, extendible in multiple ways, and is at least as efficient as D{\textless}sup{\textgreater}*{\textless}/sup{\textgreater}. We believe that our results will make D{\textless}sup{\textgreater}*{\textless}/sup{\textgreater}-like replanning methods even more popular and enable robotics researchers to adapt them to additional applications.},
annote = {This is the D*Lite Paper},
author = {Koenig, Sven and Likhachev, Maxim},
doi = {10.1109/TRO.2004.838026},
file = {::},
isbn = {0-7803-7272-7},
issn = {15523098},
journal = {IEEE Transactions on Robotics},
keywords = {A*,D* (Dynamic A*),Navigation in unknown terrain,Planning with the freespace assumption,Replanning,Search,Sensor-based path planning},
number = {3},
pages = {354--363},
title = {{Fast replanning for navigation in unknown terrain}},
volume = {21},
year = {2005}
}
@article{Yu2013,
author = {Yu, Huili and Beard, Randy},
doi = {10.1007/s10514-012-9314-z},
file = {:home/capn/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yu, Beard - 2013 - A vision-based collision avoidance technique for micro air vehicles using local-level frame mapping and path planning.pdf:pdf},
issn = {0929-5593},
journal = {Autonomous Robots},
keywords = {collision avoidance,computer vision,micro air vehicle,path planning},
number = {1-2},
pages = {93--109},
title = {{A vision-based collision avoidance technique for micro air vehicles using local-level frame mapping and path planning}},
url = {http://link.springer.com/10.1007/s10514-012-9314-z},
volume = {34},
year = {2013}
}
@article{Zhang2014,
abstract = {Visual odometry can be augmented by depth information such as provided by RGB-D cameras, or from lidars associated with cameras. However, such depth information can be limited by the sensors, leaving large areas in the visual images where depth is unavailable. Here, we propose a method to utilize the depth, even if sparsely available, in recovery of camera motion. In addition, the method utilizes depth by triangulation from the previously estimated motion, and salient visual features for which depth is unavailable. The core of our method is a bundle adjustment that refines the motion estimates in parallel by processing a sequence of images, in a batch optimization. We have evaluated our method in three sensor setups, one using an RGB-D camera, and two using combinations of a camera and a 3D lidar. Our method is rated {\#}2 on the KITTI odometry benchmark irrespective of sensing modality, and is rated {\#}1 among visual odometry methods.},
author = {Zhang, Ji and Kaess, Michael and Singh, Sanjiv},
doi = {10.1109/IROS.2014.6943269},
file = {::},
isbn = {9781479969340},
issn = {21530866},
journal = {IEEE International Conference on Intelligent Robots and Systems},
number = {Iros},
pages = {4973--4980},
title = {{Real-time depth enhanced monocular odometry}},
year = {2014}
}
@article{He2008,
abstract = {This paper describes a motion planning algorithm for a quadrotor helicopter flying autonomously without GPS. Without accurate global positioning, the vehicle's ability to localize itself varies across the environment, since different environmental features provide different degrees of localization. If the vehicle plans a path without regard to how well it can localize itself along that path, it runs the risk of becoming lost. We use the Belief Roadmap (BRM) algorithm [1], an information-space extension of the Probabilistic Roadmap algorithm, to plan vehicle trajectories that incorporate sensing. We show that the original BRM can be extended to use the Unscented Kalman Filter (UKF), and describe a sampling algorithm that minimizes the number of samples required to find a good path. Finally, we demonstrate the BRM path- planning algorithm on the helicopter, navigating in an indoor environment with a laser range-finder.},
author = {He, Ruijie and Prentice, Sam and Roy, Nicholas},
doi = {10.1109/ROBOT.2008.4543471},
file = {:home/capn/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/He, Prentice, Roy - 2008 - Planning in information space for a quadrotor helicopter in a GPS-denied environment.pdf:pdf},
isbn = {9781424416479},
issn = {10504729},
journal = {Proceedings - IEEE International Conference on Robotics and Automation},
keywords = {Collision Avoidance,Localization,Motion and Path Planning},
pages = {1814--1820},
title = {{Planning in information space for a quadrotor helicopter in a GPS-denied environment}},
year = {2008}
}
@article{Hrabar2008,
abstract = {We present a synthesis of techniques for rotorcraft UAV navigation through unknown environments which may contain obstacles. D* Lite and probabilistic roadmaps are combined for path planning, together with stereo vision for obstacle detection and dynamic path updating. A 3D occupancy map is used to represent the environment, and is updated online using stereo data. The target application is autonomous helicopter-based structure inspections, which require the UAV to fly safely close to the structures it is inspecting. Results are presented from simulation and with real flight hardware mounted onboard a cable array robot, demonstrating successful navigation through unknown environments containing obstacles.},
annote = {This is a situation where 3D stereo vision is used for map registration. An occupancy map is created using the stereo vision, and is used with D* Lite and PRM to do obstacle avoidance via planning.

Not really a contribution towards new algorithms. More just a "look what cool thing we did" paper.},
author = {Hrabar, Stefan},
doi = {10.1109/IROS.2008.4650775},
file = {:home/capn/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hrabar - 2008 - 3D path planning and stereo-based obstacle avoidance for rotorcraft UAVs.pdf:pdf},
isbn = {9781424420582},
issn = {978-1-4244-2057-5},
journal = {2008 IEEE/RSJ International Conference on Intelligent Robots and Systems, IROS},
keywords = {Autonomous helicopter,Obstacle detection,Path planning,Power line inspection,Stereo vision,UAV},
pages = {807--814},
title = {{3D path planning and stereo-based obstacle avoidance for rotorcraft UAVs}},
year = {2008}
}
@article{Scherer2009,
abstract = {When operating in partially-known environments, autonomous vehicles must constantly update their maps and plans based on new sensor information. Much focus has been placed on developing efficient incremental planning algorithms that are able to efficiently replan when the map and associated cost function changes. However, much less attention has been placed on efficiently updating the cost function used by these planners, which can represent a significant portion of the time spent replanning. In this paper, we present the limited incremental distance transform algorithm, which can be used to efficiently update the cost function used for planning when changes in the environment are observed. Using this algorithm it is possible to plan paths in a completely incremental way starting from a list of changed obstacle classifications. We present results comparing the algorithm to the Euclidean distance transform and a mask-based incremental distance transform algorithm. Computation time is reduced by an order of magnitude for a UAV application. We also provide example results from an autonomous micro aerial vehicle with on-board sensing and computing.},
author = {Scherer, S. and Ferguson, D. and Singh, S.},
doi = {10.1109/ROBOT.2009.5152790},
file = {:home/capn/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Scherer, Ferguson, Singh - 2009 - Efficient C-space and cost function updates in 3D for unmanned aerial vehicles.pdf:pdf},
isbn = {978-1-4244-2788-8},
issn = {10504729},
journal = {2009 IEEE International Conference on Robotics and Automation},
pages = {2049--2054},
title = {{Efficient C-space and cost function updates in 3D for unmanned aerial vehicles}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5152790},
year = {2009}
}
@article{Oleynikova2015,
annote = {cited flying fast and low},
author = {Oleynikova, Helen and Honegger, Dominik and Pollefeys, Marc},
file = {::},
isbn = {9781479969234},
title = {{Reactive Avoidance Using Embedded Stereo Vision for MAV Flight}},
year = {2015}
}
@article{McCarthy2004,
abstract = {We present a comparison of four optical flow methods and three spatio-temporal filters for mobile robot navigation in corridor-like environments. Previous comparisons of optical flow methods have evaluated performance only in terms of accuracy and/or efficiency, and typically in isolation. These comparisons are inadequate for addressing applicability to continuous, real-time operation as part of a robot control loop. We emphasise the need for comparisons that consider the context of a system, and that are confirmed by in-system results. To this end, we give results for on and off-board trials of two biologically inspired behaviours: corridor centring and visual odometry. Our results show the best in-system performances are achieved using Lucas and Kanade's gradient-based method in combination with a recursive temporal filter. Results for traditionally used Gaussian filters indicate that long latencies significantly impede performance for real-time tasks in the control loop.},
author = {McCarthy, C. and Barnes, N.},
doi = {10.1109/ROBOT.2004.1302525},
file = {::},
isbn = {0-7803-8232-3},
issn = {1050-4729},
journal = {{\{}IEEE International Conference on Robotics and Automation{\}}},
number = {April},
pages = {5093--5098},
title = {{Performance of optical flow techniques for indoor navigation with a mobile robot}},
volume = {2},
year = {2004}
}
@article{Hart1968,
abstract = {Although the problem of determining the minimum cost path through a graph arises naturally in a number of interesting applications, there has been no underlying theory to guide the development of efficient search procedures. Moreover, there is no adequate conceptual framework within which the various ad hoc search strategies proposed to date can be compared. This paper describes how heuristic information from the problem domain can be incorporated into a formal mathematical theory of graph searching and demonstrates an optimality property of a class of search strategies.},
author = {Hart, P.E. and Nilsson, N.J. and Raphael, B.},
doi = {10.1109/TSSC.1968.300136},
file = {::},
isbn = {0536-1567 VO - 4},
issn = {0536-1567},
journal = {IEEE Transactions on Systems Science and Cybernetics},
number = {2},
pages = {100--107},
pmid = {4082128},
title = {{A Formal Basis for the Heuristic Determination of Minimum Cost Paths}},
volume = {4},
year = {1968}
}

@article{Mnih2013,
  author    = {Volodymyr Mnih and
               Koray Kavukcuoglu and
               David Silver and
               Alex Graves and
               Ioannis Antonoglou and
               Daan Wierstra and
               Martin A. Riedmiller},
  title     = {Playing Atari with Deep Reinforcement Learning},
  journal   = {CoRR},
  volume    = {abs/1312.5602},
  year      = {2013},
  url       = {http://arxiv.org/abs/1312.5602},
  timestamp = {Wed, 01 Apr 2015 20:06:15 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/MnihKSGAWR13},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{Lillicrap2015,
  author    = {Timothy P. Lillicrap and
               Jonathan J. Hunt and
               Alexander Pritzel and
               Nicolas Heess and
               Tom Erez and
               Yuval Tassa and
               David Silver and
               Daan Wierstra},
  title     = {Continuous control with deep reinforcement learning},
  journal   = {CoRR},
  volume    = {abs/1509.02971},
  year      = {2015},
  url       = {http://arxiv.org/abs/1509.02971},
  timestamp = {Thu, 01 Oct 2015 14:28:48 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/LillicrapHPHETS15},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{Rusu2015,
  author    = {Andrei A. Rusu and
               Sergio Gomez Colmenarejo and
               {\c{C}}aglar G{\"{u}}l{\c{c}}ehre and
               Guillaume Desjardins and
               James Kirkpatrick and
               Razvan Pascanu and
               Volodymyr Mnih and
               Koray Kavukcuoglu and
               Raia Hadsell},
  title     = {Policy Distillation},
  journal   = {CoRR},
  volume    = {abs/1511.06295},
  year      = {2015},
  url       = {http://arxiv.org/abs/1511.06295},
  timestamp = {Tue, 01 Dec 2015 19:22:34 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/RusuCGDKPMKH15},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{Gatys2015,
  author    = {Leon A. Gatys and
               Alexander S. Ecker and
               Matthias Bethge},
  title     = {A Neural Algorithm of Artistic Style},
  journal   = {CoRR},
  volume    = {abs/1508.06576},
  year      = {2015},
  url       = {http://arxiv.org/abs/1508.06576},
  timestamp = {Tue, 01 Sep 2015 14:42:40 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/GatysEB15a},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{Han2015,
  author    = {Song Han and
               Huizi Mao and
               William J. Dally},
  title     = {Deep Compression: Compressing Deep Neural Network with Pruning, Trained
               Quantization and Huffman Coding},
  journal   = {CoRR},
  volume    = {abs/1510.00149},
  year      = {2015},
  url       = {http://arxiv.org/abs/1510.00149},
  timestamp = {Sun, 01 Nov 2015 17:30:45 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/HanMD15},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}


@article{LeCun2015,
author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
doi = {10.1038/nature14539},
issn = {0028-0836},
journal = {Nature},
month = {may},
number = {7553},
pages = {436--444},
publisher = {Nature Publishing Group},
title = {{Deep learning}},
url = {http://www.nature.com/doifinder/10.1038/nature14539},
volume = {521},
year = {2015}
}


@article{Rusu2016,
  author    = {Andrei A. Rusu and
               Neil C. Rabinowitz and
               Guillaume Desjardins and
               Hubert Soyer and
               James Kirkpatrick and
               Koray Kavukcuoglu and
               Razvan Pascanu and
               Raia Hadsell},
  title     = {Progressive Neural Networks},
  journal   = {CoRR},
  volume    = {abs/1606.04671},
  year      = {2016},
  url       = {http://arxiv.org/abs/1606.04671},
  timestamp = {Fri, 01 Jul 2016 17:39:49 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/RusuRDSKKPH16},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}



@book{Sutton:1998:IRL:551283,
 author = {Sutton, Richard S. and Barto, Andrew G.},
 title = {Introduction to Reinforcement Learning},
 year = {1998},
 isbn = {0262193981},
 edition = {1st},
 publisher = {MIT Press},
 address = {Cambridge, MA, USA},
} 

@article{DBLP:journals/corr/SzegedyLJSRAEVR14,
  author    = {Christian Szegedy and
               Wei Liu and
               Yangqing Jia and
               Pierre Sermanet and
               Scott E. Reed and
               Dragomir Anguelov and
               Dumitru Erhan and
               Vincent Vanhoucke and
               Andrew Rabinovich},
  title     = {Going Deeper with Convolutions},
  journal   = {CoRR},
  volume    = {abs/1409.4842},
  year      = {2014},
  url       = {http://arxiv.org/abs/1409.4842},
  timestamp = {Tue, 31 May 2016 18:15:20 +0200},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/SzegedyLJSRAEVR14},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@article{DBLP:journals/corr/TompsonGJLB14,
  author    = {Jonathan Tompson and
               Ross Goroshin and
               Arjun Jain and
               Yann LeCun and
               Christoph Bregler},
  title     = {Efficient Object Localization Using Convolutional Networks},
  journal   = {CoRR},
  volume    = {abs/1411.4280},
  year      = {2014},
  url       = {http://arxiv.org/abs/1411.4280},
  timestamp = {Mon, 01 Dec 2014 14:32:13 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/journals/corr/TompsonGJLB14},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}


@inproceedings{DBLP:conf/icra/KohlS04,
  author    = {Nate Kohl and
               Peter Stone},
  title     = {Policy Gradient Reinforcement Learning for Fast Quadrupedal Locomotion},
  booktitle = {Proceedings of the 2004 {IEEE} International Conference on Robotics
               and Automation, {ICRA} 2004, April 26 - May 1, 2004, New Orleans,
               LA, {USA}},
  pages     = {2619--2624},
  year      = {2004},
  crossref  = {DBLP:conf/icra/2004},
  url       = {http://dx.doi.org/10.1109/ROBOT.2004.1307456},
  doi       = {10.1109/ROBOT.2004.1307456},
  timestamp = {Fri, 02 Nov 2007 07:56:51 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/icra/KohlS04},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{DBLP:conf/iros/TedrakeZS04,
  author    = {Russ Tedrake and
               Teresa Weirui Zhang and
               H. Sebastian Seung},
  title     = {Stochastic policy gradient reinforcement learning on a simple 3D biped},
  booktitle = {2004 {IEEE/RSJ} International Conference on Intelligent Robots and
               Systems, Sendai, Japan, September 28 - October 2, 2004},
  pages     = {2849--2854},
  year      = {2004},
  crossref  = {DBLP:conf/iros/2004},
  url       = {http://dx.doi.org/10.1109/IROS.2004.1389841},
  doi       = {10.1109/IROS.2004.1389841},
  timestamp = {Mon, 21 Jan 2013 21:40:34 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/iros/TedrakeZS04},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{geng2005fast,
  title={Fast biped walking with a reflexive controller and real-time policy searching},
  author={Geng, Tao and Porr, Bernd and W{\"o}rg{\"o}tter, Florentin},
  booktitle={Advances in Neural Information Processing Systems},
  pages={427--434},
  year={2005}
}


@article{kober2013reinforcement,
  title={Reinforcement learning in robotics: A survey},
  author={Kober, Jens and Bagnell, J Andrew and Peters, Jan},
  journal={The International Journal of Robotics Research},
  pages={0278364913495721},
  year={2013},
  publisher={SAGE Publications}
}

@inproceedings{bagnell2001autonomous,
  title={Autonomous helicopter control using reinforcement learning policy search methods},
  author={Bagnell, J Andrew and Schneider, Jeff G},
  booktitle={Robotics and Automation, 2001. Proceedings 2001 ICRA. IEEE International Conference on},
  volume={2},
  pages={1615--1620},
  year={2001},
  organization={IEEE}
}

@article{riedmiller2009reinforcement,
  title={Reinforcement learning for robot soccer},
  author={Riedmiller, Martin and Gabel, Thomas and Hafner, Roland and Lange, Sascha},
  journal={Autonomous Robots},
  volume={27},
  number={1},
  pages={55--73},
  year={2009},
  publisher={Springer}
}

@article{riedmiller2009reinforcement,
  title={Reinforcement learning for robot soccer},
  author={Riedmiller, Martin and Gabel, Thomas and Hafner, Roland and Lange, Sascha},
  journal={Autonomous Robots},
  volume={27},
  number={1},
  pages={55--73},
  year={2009},
  publisher={Springer}
}


@inproceedings{lowe1999object,
  title={Object recognition from local scale-invariant features},
  author={Lowe, David G},
  booktitle={Computer vision, 1999. The proceedings of the seventh IEEE international conference on},
  volume={2},
  pages={1150--1157},
  year={1999},
  organization={Ieee}
}

@inproceedings{bay2006surf,
  title={Surf: Speeded up robust features},
  author={Bay, Herbert and Tuytelaars, Tinne and Van Gool, Luc},
  booktitle={European conference on computer vision},
  pages={404--417},
  year={2006},
  organization={Springer}
}

@inproceedings{rublee2011orb,
  title={ORB: An efficient alternative to SIFT or SURF},
  author={Rublee, Ethan and Rabaud, Vincent and Konolige, Kurt and Bradski, Gary},
  booktitle={2011 International conference on computer vision},
  pages={2564--2571},
  year={2011},
  organization={IEEE}
}


@incollection{thrun1995lifelong,
  title={Lifelong robot learning},
  author={Thrun, Sebastian and Mitchell, Tom M},
  booktitle={The biology and technology of intelligent autonomous agents},
  pages={165--196},
  year={1995},
  publisher={Springer}
}
